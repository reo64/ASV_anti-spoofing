{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFCC-GMM trainning baseline\n",
    "   #### number of training = 25,380\n",
    "    genuine 2,580 spoof 22,800\n",
    "   \n",
    "   #### number of development = 24,986\n",
    "    genuine 2,548 spoof 22,296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-cpf811uq because the default path (/home/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "# GMMs(Gaussian Mixture Models) front-end are LFCCs and CQCCs\n",
    "# My library\n",
    "from lfcc import *\n",
    "\n",
    "# Library for dataloader\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "# Library for LFCC-GMM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Library for reading flac audio file\n",
    "import soundfile as sf\n",
    "#from scipy.io.wavfile import read\n",
    "\n",
    "# Library for pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_formatter = \"{:.4f}\".format\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind': float_formatter})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproess, Dataset, Dataloader definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(object):\n",
    "    \"\"\"\n",
    "    Preprocessing class for audio data\n",
    "    \n",
    "    Attributes:\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        \"\"\"\n",
    "        self.extractor = None\n",
    "        self.features = None\n",
    "        \n",
    "    def __call__(self, y, sr, feature, dynamic=True):\n",
    "        \"\"\"\n",
    "        Extract fetures with lfcc, mfcc, cqcc and other method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        \"\"\"\n",
    "        if feature == 'LFCC':\n",
    "            self.extractor = LFCC(y, sr)\n",
    "            \n",
    "        elif feature == 'MFCC':\n",
    "            self.extractor = MFCC(y, sr)\n",
    "        \n",
    "        elif feature == 'CQCC':\n",
    "            self.extractor = CQCC(y, sr)\n",
    "        \n",
    "        self.features = self.extractor.extract_feature(delta=True)\n",
    "        \n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_evaluation.ipynb  eval_metrics.py\t\tlibCB_v01.py\r\n",
      "cm_LA_LFCC_frame.score\t   evaluate_tDCF_asvspoof19.py\tmfcc.py\r\n",
      "cqcc.py\t\t\t   GMM_sequential.ipynb\t\tmodels\r\n",
      "dask-worker-space\t   GMMs_train.ipynb\t\t__pycache__\r\n",
      "datasets\t\t   gmm_train.py\t\t\tpytorch_gmm.ipynb\r\n",
      "em_algorithm.py\t\t   LA_T_1028533.flac\t\tscores\r\n",
      "em_algorithm_v2.py\t   lfcc.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s1260057/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1827\n",
      "  warnings.warn(\n",
      "/home/s1260057/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=914\n",
      "  warnings.warn(\n",
      "/home/s1260057/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=457\n",
      "  warnings.warn(\n",
      "/home/s1260057/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=229\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(864, 229)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "y, sr = sf.read('LA_T_1028533.flac')\n",
    "\n",
    "B = 96 # number of bins per octave\n",
    "fmax = sr//2\n",
    "fmin = fmax/(2**9) # 9 being number of octave\n",
    "fbas = B * int(np.log2(fmax/fmin))\n",
    "print(fbas)\n",
    "\n",
    "x_fea = librosa.cqt(y, sr, hop_length=(2**7)*1, fmin=fmin, n_bins=fbas, bins_per_octave=B,\n",
    "                    tuning=None, norm=len(y), sparsity=0)\n",
    "x_fea = np.abs(x_fea)\n",
    "x_fea.shape # This should be 863, 214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "step_length: 160\n",
      "wave_length: 29219, frame_length: 320, nshift: 181\n",
      "[-17.7583 -0.5317 0.4484 0.3518 -0.2962]\n",
      "[-18.0314 -0.4648 0.3014 0.3144 0.1563]\n",
      "[-17.8703 -0.4279 -0.0296 0.1293 -0.0894]\n",
      "[-17.9633 -0.3921 0.5168 0.5181 0.2447]\n",
      "[-17.9169 -0.2804 0.0427 0.5191 0.1362]\n",
      "(181, 60)\n"
     ]
    }
   ],
   "source": [
    "y, sr = sf.read('LA_T_1028533.flac')\n",
    "\n",
    "print(sr*20//1000)\n",
    "\n",
    "extractor = LFCC(y, sr)\n",
    "lfcc = extractor.extract_feature(delta=True).T\n",
    "\n",
    "for i in range(5):\n",
    "    print(lfcc[i][:5])\n",
    "    \n",
    "print(lfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_datapath_list(phase='train'):\n",
    "    \"\"\"\n",
    "    make a list containing a path to data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    phase: 'train' or 'dev' or 'eval'\n",
    "        specify whether data is for train or development or evaluation\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    path_list : list\n",
    "        return a list containing a path to data\n",
    "    \"\"\"\n",
    "    \n",
    "    root_path = \"/DB/Audio/English/ASVspoof2019/LA/\"\n",
    "    target_path = os.path.join(root_path+'ASVspoof2019_LA_'+phase+'/flac/*.flac')\n",
    "    print(target_path)\n",
    "    \n",
    "    path_list = []\n",
    "    \n",
    "    # Get a filepath to subdir by using glob module\n",
    "    for path in sorted(glob.glob(target_path)):\n",
    "        path_list.append(path)\n",
    "    \n",
    "    return path_list\n",
    "\n",
    "# test\n",
    "train_list = make_datapath_list(phase='train')\n",
    "dev_list = make_datapath_list(phase='dev')\n",
    "\n",
    "#print(train_list)\n",
    "\n",
    "#print(dev_list)\n",
    "\n",
    "#print(len(train_list), len(dev_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataloader\n",
    "class ASVspoofDataSet(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for ASVspoof2019, which derived from torch.utils.data.Dataset class\n",
    "    \n",
    "    Attributes:\n",
    "    --------------\n",
    "    file_list: list\n",
    "        list containing a path to data\n",
    "        \n",
    "    transform: object\n",
    "        instance of PreProcessor\n",
    "    \n",
    "    phase: str\n",
    "        'train' or 'dev' or 'eval'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_list, label_list=None, preprocess=None, phase='train'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_list: list\n",
    "            list of audio files to read\n",
    "        \n",
    "        label_list: list\n",
    "            list of labels('bonafide' or 'spoof'), which is changed to 0, 1\n",
    "        \n",
    "        transform: class PreProcess\n",
    "            instance of PreProcess to be used for pre-process to audio data\n",
    "        \n",
    "        phase: str\n",
    "            specify whether data is for training or development or evaluation('train' or 'dev' or 'eval')\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.phase = phase\n",
    "        self.preprocess = preprocess\n",
    "        self.root_path = '/DB/Audio/English/ASVspoof2019/LA/'\n",
    "        #self.file_path = None\n",
    "        self.file_list = file_list\n",
    "        self.label_path = None\n",
    "        self.label_list = label_list\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            self.label_path = os.path.join(self.root_path+'ASVspoof2019_LA_cm_protocols/')\n",
    "            self.label_list = []\n",
    "            with open(self.label_path+'ASVspoof2019.LA.cm.train.trn.txt', mode='r') as protocols:\n",
    "                for line in protocols:\n",
    "                    line = line.split() # read line by line\n",
    "                    filename, label = line[1], line[-1] # get filename and label from protocols file\n",
    "                    self.label_list.append((filename, label))\n",
    "                    \n",
    "        elif self.phase == 'dev':\n",
    "            self.label_path = os.path.join(self.root_path+'ASVspoof2019_LA_cm_protocols/')\n",
    "            self.label_list = []\n",
    "            with open(self.label_path+'ASVspoof2019.LA.cm.dev.trl.txt', mode='r') as protocols:\n",
    "                for line in protocols:\n",
    "                    line = line.split() # read line by line\n",
    "                    filename, label = line[1], (line[0], line[3], line[-1]) # get items from protocols file\n",
    "                    self.label_list.append((filename, label))\n",
    "        else:\n",
    "            print(\"You must pass either phase='train' or phase='dev'\")\n",
    "        \n",
    "    def __len__(self): # this is needed to be overrided\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index): # this is also needed to be overrided\n",
    "        \"\"\"\n",
    "        Get data and its label that was pre-processed\n",
    "        \"\"\"\n",
    "        \n",
    "        # load audio\n",
    "        speech_path = self.file_list[index]\n",
    "        speech, sr = sf.read(speech_path)\n",
    "        \n",
    "        # preprocessing and extract features\n",
    "        features = self.preprocess(y=speech, sr=sr, feature='LFCC')\n",
    "        \n",
    "        label = None\n",
    "        \n",
    "        speech_name = speech_path.split('/')[-1].rstrip('.flac')\n",
    "        \n",
    "        for fname, key in self.label_list:\n",
    "            #print(fname)\n",
    "            if fname == speech_name: # compare to speech_name with '==' annotation, check if they have same value.\n",
    "                label = key\n",
    "                #print(\"filename: {}, label: {}\".format(fname, label))\n",
    "        \n",
    "        #print(\"sp name:\", speech_name)\n",
    "        if label is None:\n",
    "            pass\n",
    "            #print('[debug print] filename:', speech_name)\n",
    "            \n",
    "        return features, label\n",
    "    \n",
    "# test\n",
    "\n",
    "asvspoof_train = ASVspoofDataSet(file_list=train_list, preprocess=process, phase='train')\n",
    "\n",
    "# get 10 files and its label\n",
    "iterations = 10\n",
    "\n",
    "for itr in range(iterations):\n",
    "    #print(asvspoof_train.file_list[itr])\n",
    "    feature, label = asvspoof_train.__getitem__(itr)\n",
    "    print(\"60 vectors\", feature.T.shape)\n",
    "    print(\"audiofile label: \", label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling number of bonafide 'file' from spoofed speech 'file'\n",
    "# n_bonafide file = 2,580\n",
    "# n_spoof file = 22,800\n",
    "\"\"\"\n",
    "n_bonafide_file = 2580\n",
    "\n",
    "genuine_list = []\n",
    "spoof_list = []\n",
    "\n",
    "for fname, la in asvspoof_train.label_list:\n",
    "    if la == 'bonafide':\n",
    "        genuine_list.append(fname)\n",
    "    else:\n",
    "        spoof_list.append(fname)\n",
    "\n",
    "print(len(genuine_list),len(spoof_list))\n",
    "\n",
    "# randomly sample n_bonafide data from spoof list\n",
    "downsampled = np.random.choice(spoof_list, size=n_bonafide_file, replace=False)\n",
    "\n",
    "spoof_list = downsampled\n",
    "print(len(spoof_list))\n",
    "print(genuine_list[:4])\n",
    "print(spoof_list[:4])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Making csv undersampled dataset for GMMs\n",
    "##########################################\n",
    "#! This method doesnt use asvdataset.__getitem__\n",
    "\"\"\"\n",
    "train_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_train/flac/'\n",
    "\n",
    "genuine_df = pd.DataFrame()\n",
    "\n",
    "total = len(genuine_list)\n",
    "count = 0\n",
    "print('total file', total)\n",
    "\n",
    "progress=np.linspace(10,100,10)\n",
    "\n",
    "for fname in genuine_list:\n",
    "    # spoof_list is undersampled\n",
    "    prog = count/total*100\n",
    "    if prog in progress:\n",
    "        print('{}% complete'.format(prog))\n",
    "\n",
    "    # load audio\n",
    "    speech, sr = sf.read(train_path+fname+'.flac')\n",
    "    # preprocessing and extract features\n",
    "    features = process(y=speech, sr=sr, feature='LFCC') # preprocess to speech, not implemented yet\n",
    "\n",
    "    feature_df = pd.DataFrame(feature.T)\n",
    "\n",
    "    genuine_df = genuine_df.append(feature_df, ignore_index=True)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "print('end')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "##########################################\n",
    "# Making csv undersampled dataset for GMMs\n",
    "##########################################\n",
    "#! This method doesnt use asvdataset.__getitem__\n",
    "\n",
    "train_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_train/flac/'\n",
    "\n",
    "spoofed_df = pd.DataFrame()\n",
    "\n",
    "total = len(spoof_list)\n",
    "count = 0\n",
    "print('total file', total)\n",
    "\n",
    "progress=np.linspace(10,100,10)\n",
    "\n",
    "for file in spoof_list:\n",
    "    # spoof_list is undersampled\n",
    "    prog = count/total*100\n",
    "    if prog in progress:\n",
    "        print('{}% complete'.format(prog))\n",
    "\n",
    "    # load audio\n",
    "    speech, sr = sf.read(train_path+file+'.flac')\n",
    "    # preprocessing and extract features\n",
    "    features = process(y=speech, sr=sr, feature='LFCC') # preprocess to speech, not implemented yet\n",
    "\n",
    "    feature_df = pd.DataFrame(feature.T)\n",
    "    \n",
    "    spoofed_df = spoofed_df.append(feature_df, ignore_index=True)\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "print('end')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMMs training section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters for training\n",
    "\n",
    "LFCCs:\n",
    "\n",
    "    window_len = 20ms\n",
    "    nfft = 512\n",
    "    # of filters = 20\n",
    "    dynamic features = delta, delta-delta included\n",
    "\n",
    "GMMs:\n",
    "\n",
    "    n_components = 512\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# instanciate DataLoader\n",
    "train_dataloader = data.DataLoader(asvspoof_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = None #data.DataLoader()\n",
    "\n",
    "dataloader_dict = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader\n",
    "}\n",
    "\n",
    "batch_iterator = iter(dataloader_dict[\"train\"])\n",
    "inputs, labels = next(batch_iterator) # get first element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_train/flac/*'\n",
    "\n",
    "speech_count = 0\n",
    "total = len(glob.glob(train_path))\n",
    "print(\"total_speech:\", total)\n",
    "\n",
    "genuine_df = pd.DataFrame()\n",
    "spoofed_df = pd.DataFrame()\n",
    "\n",
    "progress=np.linspace(10,100,10)\n",
    "\n",
    "for itr in range(total):\n",
    "    \n",
    "    prog = speech_count/total*100\n",
    "    \n",
    "    if prog in progress:\n",
    "        print('{}% complete'.format(prog))\n",
    "    \n",
    "    feature, label = asvspoof_train.__getitem__(itr)\n",
    "    #print(\"12-dimentional vectors\", feature.T.shape)\n",
    "    #print(\"audiofile label: \", label)\n",
    "    #print()\n",
    "    feature_df = pd.DataFrame(feature.T)\n",
    "    \n",
    "    #print(feature_df.shape)\n",
    "    if label == 'bonafide':\n",
    "        genuine_df = genuine_df.append(feature_df, ignore_index=True)\n",
    "    else:\n",
    "        spoofed_df = spoofed_df.append(feature_df, ignore_index=True)\n",
    "    \n",
    "    speech_count += 1\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, label = asvspoof_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence-based-scaling npy file save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sentence based scaling dataset\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_train/flac/*'\n",
    "\n",
    "lfcc_scaled_bona = np.array([]).reshape(0, 60)\n",
    "lfcc_scaled_spoof = np.array([]).reshape(0, 60)\n",
    "\n",
    "for itr in range(len(asvspoof_train)):\n",
    "    \n",
    "    feature, label = asvspoof_train.__getitem__(itr)\n",
    "    \n",
    "    np.save('./datasets/original/train/lfcc/{}_{}'.format(label, itr), feature.T)\n",
    "    \n",
    "    feature_scaled = preprocessing.scale(feature.T)\n",
    "    \n",
    "    #print(feature_scaled.shape, feature_scaled.mean(axis=0)[:4], feature_scaled.std(axis=0)[:4])\n",
    "    np.save('./datasets/scaled/train/lfcc/{}_{}'.format(label, itr), feature_scaled)\n",
    "    \n",
    "    if label == 'bonafide':\n",
    "        lfcc_scaled_bona = np.vstack((lfcc_scaled_bona, feature_scaled))\n",
    "    else:\n",
    "        lfcc_scaled_spoof = np.vstack((lfcc_scaled_spoof, feature_scaled))\n",
    "\n",
    "print('end')\n",
    "print(lfcc_scaled_bona.shape)# should be 542574\n",
    "print(lfcc_scaled_spoof.shape)# should be 4853674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stacking lfcc matrix calculated by sentence-based-scaling\n",
    "np.save('./datasets/scaled/train/lfcc/all_bonafide.npy', lfcc_scaled_bona)\n",
    "np.save('./datasets/scaled/train/lfcc/all_spoof.npy', lfcc_scaled_spoof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load('./datasets/scaled/train/all_data_lfcc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "asvspoof_dev = ASVspoofDataSet(file_list=dev_list, preprocess=process, phase='dev')\n",
    "\n",
    "#lfcc_scaled_bona_dev = np.array([]).reshape(0, 60)\n",
    "#lfcc_scaled_spoof_dev = np.array([]).reshape(0, 60)\n",
    "\n",
    "for itr in range(len(asvspoof_dev)):\n",
    "    \n",
    "    feature, label = asvspoof_dev.__getitem__(itr)\n",
    "    \n",
    "    if label is None:\n",
    "        continue\n",
    "    \n",
    "    np.save('./datasets/original/dev/lfcc/{}_{}.npy'.format(label[-1], itr), feature.T)\n",
    "    \n",
    "    feature_scaled = preprocessing.scale(feature.T)\n",
    "    #print(label)\n",
    "    #print(feature_scaled.shape, feature_scaled.mean(axis=0)[:4], feature_scaled.std(axis=0)[:4])\n",
    "    np.save('./datasets/scaled/dev/lfcc/{}_{}.npy'.format(label[-1], itr), feature_scaled)\n",
    "    \n",
    "    #lfcc_scaled = np.vstack((lfcc_scaled, feature_scaled))\n",
    "    \n",
    "print('end')\n",
    "#print(lfcc_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(genuine_df), len(spoofed_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove inf and nan from genuine_df and spoofed_df\n",
    "\n",
    "genuine_df.replace([np.inf, -np.inf], np.nan).dropna(inplace=True)\n",
    "genuine_df.reset_index(drop=True).to_csv('./datasets/lfcc_genuine_downsampled.csv', index=False)\n",
    "\n",
    "spoofed_df.replace([np.inf, -np.inf], np.nan).dropna(inplace=True)\n",
    "spoofed_df.reset_index(drop=True).to_csv('./datasets/lfcc_spoofed_downsampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg = pd.read_csv('./datasets/lfcc_genuine.csv')\n",
    "\n",
    "n_genuine = Xg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n_genuine:{}, n_spoofed:{}'.format(n_genuine, n_spoofed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMMs training\n",
    "\n",
    "#Xg = pd.read_csv('./lfcc_genuine.csv')\n",
    "\n",
    "# speaker embedding by using GMMs, where n_components = 512\n",
    "n_components = 512\n",
    "\n",
    "genuine_gmms = GaussianMixture(n_components=n_components, covariance_type='diag', init_params='random', max_iter=10, random_state=None)\n",
    "\n",
    "# Train the other parameters using the EM algorithm\n",
    "genuine_gmms.fit(Xg)\n",
    "\n",
    "Xg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = pd.read_csv('./datasets/lfcc_spoofed.csv')\n",
    "\n",
    "n_spoofed = Xs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n_genuine:{}, n_spoofed:{}'.format(n_genuine, n_spoofed), n_genuine+n_spoofed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_downsampled_idx = np.random.choice(np.arange(n_spoofed), size=n_genuine, replace=False)\n",
    "\n",
    "print(Xs_downsampled_idx.shape)\n",
    "\n",
    "Xs_new = Xs.loc[Xs_downsampled_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "#Xs = pd.read_csv('./lfcc_spoofed.csv')\n",
    "\n",
    "n_components = 512\n",
    "\n",
    "#n_sample = Xs.shape[0]\n",
    "\n",
    "spoofed_gmms = GaussianMixture(n_components=n_components, covariance_type='diag', init_params='random', max_iter=10, random_state=None)\n",
    "\n",
    "# Train the other parameters using the EM algorithm\n",
    "spoofed_gmms.fit(Xs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(genuine_gmms, 'genuine_gmms.model')\n",
    "joblib.dump(spoofed_gmms, 'spoofed_gmms.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "asvspoof_dev = ASVspoofDataSet(file_list=dev_list, preprocess=process, phase='dev')\n",
    "\n",
    "# get 10 files and its label\n",
    "iterations = 10\n",
    "\n",
    "for itr in range(iterations):\n",
    "    feature, label = asvspoof_dev.__getitem__(itr)\n",
    "    #print(\"60 vectors\", feature.T.shape)\n",
    "    print(\"audiofile label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "genuine_gmms = joblib.load('./models/genuine_gmms.model')\n",
    "\n",
    "spoofed_gmms = joblib.load('./models/spoofed_gmms.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dev_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_dev/flac/*'\n",
    "\n",
    "speech_count = 0\n",
    "total = len(glob.glob(dev_path))\n",
    "print(\"total_speech:\", total)\n",
    "\n",
    "progress=np.arange(10.0,110.0,10)\n",
    "\n",
    "cm_LA_LFCC = []\n",
    "\n",
    "for itr in range(total):\n",
    "    \n",
    "    prog = speech_count/total*100\n",
    "    if prog in progress:\n",
    "        print('%.2f % complete' % prog)\n",
    "    \n",
    "    feature, label = asvspoof_dev.__getitem__(itr)\n",
    "    \n",
    "    # compute log-likelihood ratio\n",
    "    score = genuine_gmms.score(feature.T) - spoofed_gmms.score(feature.T)\n",
    "    \n",
    "    if label is None:\n",
    "        continue\n",
    "    cm_LA_LFCC.append((*label, score))\n",
    "\n",
    "print('Done!')\n",
    "print(len(cm_LA_LFCC))\n",
    "#np.savetxt('scores_cm_LA_LFCC.txt', score, fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cm_LA_LFCC) # This should be 24844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scores_cm_LA_LFCC.txt', mode='w') as f:\n",
    "    \n",
    "    f.write('\\n'.join('{} {} {} {}'.format(x[0], x[1], x[2], x[3]) for x in cm_LA_LFCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('scores_cm_LA_LFCC.txt', mode='r') as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./scores_cm_LA_LFCC.txt ./scores/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cm_LA_LFCC, 'cm_LA_LFCC.score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
