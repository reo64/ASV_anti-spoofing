{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-9e2crdfr because the default path (/home/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "# GMMs(Gaussian Mixture Models) front-end are LFCCs and CQCCs.\n",
    "# My library\n",
    "#from lfcc import *\n",
    "\n",
    "# Library for dataloader\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "# Library for LFCC-GMM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "#from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Library for reading flac audio file\n",
    "import soundfile as sf\n",
    "#from scipy.io.wavfile import read\n",
    "\n",
    "# Library for pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import pycave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_formatter = \"{:.4f}\".format\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind': float_formatter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(object):\n",
    "    \"\"\"\n",
    "    Preprocessing class for audio data\n",
    "    \n",
    "    Attributes:\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        \"\"\"\n",
    "        self.extractor = None\n",
    "        self.features = None\n",
    "        \n",
    "    def __call__(self, y, sr, feature, dynamic=True):\n",
    "        \"\"\"\n",
    "        Extract fetures with lfcc, mfcc, cqcc and other method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        \"\"\"\n",
    "        if feature == 'LFCC':\n",
    "            self.extractor = LFCC(y, sr)\n",
    "            \n",
    "        elif feature == 'MFCC':\n",
    "            self.extractor = MFCC(y, sr)\n",
    "        \n",
    "        elif feature == 'CQCC':\n",
    "            self.extractor = CQCC(y, sr)\n",
    "        else:\n",
    "            print('Wrong feature extraction method specified')\n",
    "            return None\n",
    "        \n",
    "        self.features = self.extractor.extract_feature(delta=True)\n",
    "        \n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_train/flac/*.flac\n",
      "/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_dev/flac/*.flac\n"
     ]
    }
   ],
   "source": [
    "def make_datapath_list(phase='train'):\n",
    "    \"\"\"\n",
    "    make a list containing a path to data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    phase: 'train' or 'dev' or 'eval'\n",
    "        specify whether data is for train or development or evaluation\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    path_list : list\n",
    "        return a list containing a path to data\n",
    "    \"\"\"\n",
    "    \n",
    "    root_path = \"/DB/Audio/English/ASVspoof2019/LA/\"\n",
    "    target_path = os.path.join(root_path+'ASVspoof2019_LA_'+phase+'/flac/*.flac')\n",
    "    print(target_path)\n",
    "    \n",
    "    path_list = []\n",
    "    \n",
    "    # Get a filepath to subdir by using glob module\n",
    "    for path in sorted(glob.glob(target_path)):\n",
    "        path_list.append(path)\n",
    "    \n",
    "    return path_list\n",
    "\n",
    "# test\n",
    "train_list = make_datapath_list(phase='train')\n",
    "dev_list = make_datapath_list(phase='dev')\n",
    "\n",
    "#print(train_list)\n",
    "\n",
    "#print(dev_list)\n",
    "\n",
    "#print(len(train_list), len(dev_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 vectors (155, 60)\n",
      "audiofile label:  spoof\n",
      "\n",
      "60 vectors (177, 60)\n",
      "audiofile label:  bonafide\n",
      "\n",
      "60 vectors (119, 60)\n",
      "audiofile label:  spoof\n",
      "\n",
      "60 vectors (140, 60)\n",
      "audiofile label:  spoof\n",
      "\n",
      "60 vectors (234, 60)\n",
      "audiofile label:  spoof\n",
      "\n",
      "60 vectors (206, 60)\n",
      "audiofile label:  spoof\n",
      "\n",
      "60 vectors (178, 60)\n",
      "audiofile label:  spoof\n",
      "\n",
      "60 vectors (143, 60)\n",
      "audiofile label:  spoof\n",
      "\n",
      "60 vectors (122, 60)\n",
      "audiofile label:  spoof\n",
      "\n",
      "60 vectors (111, 60)\n",
      "audiofile label:  spoof\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make dataloader\n",
    "class ASVspoofDataSet(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for ASVspoof2019, which derived from torch.utils.data.Dataset class\n",
    "    \n",
    "    Attributes:\n",
    "    --------------\n",
    "    file_list: list\n",
    "        list containing a path to data\n",
    "        \n",
    "    transform: object\n",
    "        instance of PreProcessor\n",
    "    \n",
    "    phase: str\n",
    "        'train' or 'dev' or 'eval'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_list, label_list=None, preprocess=None, phase='train'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_list: list\n",
    "            list of audio files to read\n",
    "        \n",
    "        label_list: list\n",
    "            list of labels('bonafide' or 'spoof'), which is changed to 0, 1\n",
    "        \n",
    "        transform: class PreProcess\n",
    "            instance of PreProcess to be used for pre-process to audio data\n",
    "        \n",
    "        phase: str\n",
    "            specify whether data is for training or development or evaluation('train' or 'dev' or 'eval')\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.phase = phase\n",
    "        self.preprocess = preprocess\n",
    "        self.root_path = '/DB/Audio/English/ASVspoof2019/LA/'\n",
    "        #self.file_path = None\n",
    "        self.file_list = file_list\n",
    "        self.label_path = None\n",
    "        self.label_list = label_list\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            self.label_path = os.path.join(self.root_path+'ASVspoof2019_LA_cm_protocols/')\n",
    "            self.label_list = []\n",
    "            with open(self.label_path+'ASVspoof2019.LA.cm.train.trn.txt', mode='r') as protocols:\n",
    "                for line in protocols:\n",
    "                    line = line.split() # read line by line\n",
    "                    filename, label = line[1], line[-1] # get filename and label from protocols file\n",
    "                    self.label_list.append((filename, label))\n",
    "                    \n",
    "        elif self.phase == 'dev':\n",
    "            self.label_path = os.path.join(self.root_path+'ASVspoof2019_LA_cm_protocols/')\n",
    "            self.label_list = []\n",
    "            with open(self.label_path+'ASVspoof2019.LA.cm.dev.trl.txt', mode='r') as protocols:\n",
    "                for line in protocols:\n",
    "                    line = line.split() # read line by line\n",
    "                    filename, label = line[1], (line[0], line[3], line[-1]) # get items from protocols file\n",
    "                    self.label_list.append((filename, label))\n",
    "        else:\n",
    "            print(\"You must pass either phase='train' or phase='dev'\")\n",
    "        \n",
    "    def __len__(self): # this is needed to be overrided\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index): # this is also needed to be overrided\n",
    "        \"\"\"\n",
    "        Get data and its label that was pre-processed\n",
    "        \"\"\"\n",
    "        \n",
    "        # load audio\n",
    "        speech_path = self.file_list[index]\n",
    "        speech, sr = sf.read(speech_path)\n",
    "        \n",
    "        # preprocessing and extract features\n",
    "        features = self.preprocess(y=speech, sr=sr, feature='LFCC') # preprocess to speech, not implemented yet\n",
    "        \n",
    "        label = None\n",
    "        \n",
    "        speech_name = speech_path.split('/')[-1].rstrip('.flac')\n",
    "        \n",
    "        for fname, key in self.label_list:\n",
    "            #print(fname)\n",
    "            if fname == speech_name: # compare to speech_name with '==' annotation, check if they have same value.\n",
    "                label = key\n",
    "                #print(\"filename: {}, label: {}\".format(fname, label))\n",
    "        #print(\"sp name:\", speech_name)\n",
    "        if label is None:\n",
    "            print('[debug print] filename:', speech_name)\n",
    "        \n",
    "        #features = torch.from_numpy(features)\n",
    "        #print(type(features))\n",
    "        return features, label\n",
    "    \n",
    "# test\n",
    "\n",
    "process = Preprocess()\n",
    "\n",
    "asvspoof_train = ASVspoofDataSet(file_list=train_list, preprocess=process, phase='train')\n",
    "\n",
    "# get 10 files and its label\n",
    "iterations = 10\n",
    "\n",
    "for itr in range(iterations):\n",
    "    #print(asvspoof_train.file_list[itr])\n",
    "    feature, label = asvspoof_train.__getitem__(itr)\n",
    "    print(\"60 vectors\", feature.T.shape)\n",
    "    print(\"audiofile label: \", label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# instanciate DataLoader\n",
    "train_dataloader = data.DataLoader(asvspoof_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = None #data.DataLoader()\n",
    "\n",
    "dataloader_dict = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader\n",
    "}\n",
    "\n",
    "#batch_iterator = iter(dataloader_dict[\"train\"])\n",
    "#inputs, labels = next(batch_iterator) # get first element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg = pd.read_csv('./datasets/lfcc_genuine.csv')\n",
    "\n",
    "n_genuine = Xg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Xs = pd.read_csv('./datasets/lfcc_spoofed.csv')\n",
    "\n",
    "n_spoofed = Xs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n_genuine:{}, n_spoofed:{}'.format(n_genuine, n_spoofed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import normalize\n",
    "# Get tensor from numpy array\n",
    "# DataFrame -> Numpy array -> normalize -> torch.tensor\n",
    "Xg_normalized = normalize(Xg, norm='l2')\n",
    "print(Xg_normalized.shape)\n",
    "\n",
    "Xg_tensor = torch.from_numpy(Xg_normalized).float()\n",
    "\n",
    "print(Xg_tensor.max(), Xg_tensor.min())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution::: Number of frames are changed as windowlength is changed as well\n",
    "# shape = (873016, 60)\n",
    "bonafide_df = pd.read_csv('./datasets/lfcc_bonafide_winlen20ms.csv')\n",
    "bonafide_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "\n",
    "mat_g = hdf5storage.loadmat('./datasets/genuineFeatureLFCC_v2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_s = hdf5storage.loadmat('./datasets/spoofFeatureLFCC_v2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg = bonafide_df.to_numpy()\n",
    "Xg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.array(loadmat('./datasets/spoofFeatureLFCC.mat'))\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution::: Number of frames are changed as windowlength is changed as well\n",
    "# shape = (7809362, 60)\n",
    "spoof_df = pd.read_csv('./datasets/lfcc_spoof_winlen20ms.csv')\n",
    "spoof_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = spoof_df[:5000000].to_numpy()4853674\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM training for bonafide class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling training set with mu=0, std=1\n",
    "sscaler = StandardScaler()\n",
    "sscaler.fit(Xg)\n",
    "Xg_scaled = sscaler.transform(Xg)\n",
    "\n",
    "print(Xg_scaled.mean(axis=0))\n",
    "print(Xg_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg_scaled = np.load('./datasets/scaled/train/all_bonafide.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg_tensor_scaled = torch.from_numpy(Xg_scaled).float()\n",
    "print(Xg_tensor_scaled.mean(axis=0))\n",
    "print(Xg_tensor_scaled.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg_tensor = torch.from_numpy(mat_g['genuine_matrix']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([873016, 60])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xg_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycave.bayes import GMM\n",
    "gmm_bonafide = GMM(num_components=512, num_features=60, covariance='diag')\n",
    "gmm_bonafide.reset_parameters(max_iter=10)\n",
    "history_g = gmm_bonafide.fit(Xg_tensor, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "component_weights \t tensor(1.0000)\n",
      "gaussian.means \t tensor(-1842.4930)\n",
      "gaussian.covars \t tensor(23294.2891)\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in gmm_bonafide.state_dict():\n",
    "    print(param_tensor, \"\\t\", gmm_bonafide.state_dict()[param_tensor].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[168.67047119140625,\n",
       " 36.3994140625,\n",
       " 34.30910110473633,\n",
       " 33.611724853515625,\n",
       " 33.21047592163086,\n",
       " 32.96519470214844,\n",
       " 32.80242919921875,\n",
       " 32.68584442138672,\n",
       " 32.59552764892578,\n",
       " 32.52019119262695,\n",
       " 32.45286178588867,\n",
       " 32.39021301269531,\n",
       " 32.331642150878906,\n",
       " 32.27769088745117,\n",
       " 32.228145599365234,\n",
       " 32.18339157104492,\n",
       " 32.14390182495117,\n",
       " 32.10991668701172,\n",
       " 32.08110427856445,\n",
       " 32.05655288696289]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_g.neg_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(gmm_bonafide.state_dict(), './models/lfcc_gmm_bonafide_winlen20ms_mat.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMM(\n",
       "  (gaussian): Gaussian(dim=60)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an instance with trained parameters\n",
    "from pycave.bayes import GMM\n",
    "gmm_bonafide = GMM(num_components=512, num_features=60, covariance='diag')\n",
    "gmm_bonafide.load_state_dict(torch.load('./models/lfcc_gmm_bonafide_winlen20ms_mat.pt'))\n",
    "gmm_bonafide.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "component_weights \t tensor(1.0000)\n",
      "gaussian.means \t tensor(-1842.4930)\n",
      "gaussian.covars \t tensor(23294.2891)\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "# Confirmation, make sure saved model and trained model have same parameters.\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in gmm_bonafide.state_dict():\n",
    "    print(param_tensor, \"\\t\", gmm_bonafide.state_dict()[param_tensor].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM training for spoof class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling training set with mu=0, std=1\n",
    "sscaler = StandardScaler()\n",
    "sscaler.fit(Xs)\n",
    "Xs_scaled = sscaler.transform(Xs)\n",
    "\n",
    "print(Xs_scaled.mean(axis=0))\n",
    "print(Xs_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_scaled = np.load('./datasets/scaled/train/lfcc/all_spoof.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_tensor = torch.from_numpy(Xs_scaled).float()\n",
    "print(Xs_tensor.mean(axis=0))\n",
    "print(Xs_tensor.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_tensor = torch.from_numpy(Xs).float()\n",
    "Xs_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del spoof_df, Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7809362, 60])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_tensor = torch.from_numpy(mat_s['spoof_matrix']).float()\n",
    "Xs_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a model for spoof\n",
    "from pycave.bayes import GMM\n",
    "\n",
    "gmm_spoof = GMM(num_components=512, num_features=60, covariance='diag')\n",
    "gmm_spoof.reset_parameters(max_iter=10)\n",
    "history_s = gmm_spoof.fit(Xs_tensor, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "component_weights \t tensor(1.)\n",
      "gaussian.means \t tensor(-1898.5071)\n",
      "gaussian.covars \t tensor(24112.1504)\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in gmm_spoof.state_dict():\n",
    "    print(param_tensor, \"\\t\", gmm_spoof.state_dict()[param_tensor].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[169.619140625,\n",
       " 35.970855712890625,\n",
       " 33.644657135009766,\n",
       " 32.65544128417969,\n",
       " 32.084747314453125,\n",
       " 31.698017120361328,\n",
       " 31.38581085205078,\n",
       " 31.109220504760742,\n",
       " 30.85027313232422,\n",
       " 30.638986587524414,\n",
       " 30.48299217224121,\n",
       " 30.370349884033203,\n",
       " 30.285409927368164,\n",
       " 30.216463088989258,\n",
       " 30.156810760498047,\n",
       " 30.1041259765625,\n",
       " 30.054887771606445,\n",
       " 30.007131576538086,\n",
       " 29.965469360351562,\n",
       " 29.93009376525879]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_s.neg_log_likelihood\n",
    "#history_s.batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for bonafide\n",
    "torch.save(gmm_spoof.state_dict(), './models/lfcc_gmm_spoof_win20ms_mat.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMM(\n",
       "  (gaussian): Gaussian(dim=60)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an instance with trained parameters\n",
    "from pycave.bayes import GMM\n",
    "\n",
    "gmm_spoof = GMM(num_components=512, num_features=60, covariance='diag')\n",
    "gmm_spoof.load_state_dict(torch.load('./models/lfcc_gmm_spoof_win20ms_mat.pt'))\n",
    "gmm_spoof.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "component_weights \t tensor(1.)\n",
      "gaussian.means \t tensor(-1898.5071)\n",
      "gaussian.covars \t tensor(24112.1504)\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "# Confirmation, make sure saved model and trained model have same parameters.\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in gmm_spoof.state_dict():\n",
    "    print(param_tensor, \"\\t\", gmm_spoof.state_dict()[param_tensor].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audiofile label: ('LA_0075', 'A01', 'spoof')\n",
      "audiofile label: ('LA_0076', 'A05', 'spoof')\n",
      "audiofile label: ('LA_0072', 'A06', 'spoof')\n",
      "audiofile label: ('LA_0077', 'A04', 'spoof')\n",
      "audiofile label: ('LA_0070', 'A04', 'spoof')\n",
      "audiofile label: ('LA_0078', 'A04', 'spoof')\n",
      "audiofile label: ('LA_0071', 'A06', 'spoof')\n",
      "audiofile label: ('LA_0069', 'A05', 'spoof')\n",
      "audiofile label: ('LA_0078', 'A04', 'spoof')\n",
      "audiofile label: ('LA_0075', 'A04', 'spoof')\n"
     ]
    }
   ],
   "source": [
    "# Development dataset for validation\n",
    "\n",
    "asvspoof_dev = ASVspoofDataSet(file_list=dev_list, preprocess=process, phase='dev')\n",
    "\n",
    "# get 10 files and its label\n",
    "iterations = 10\n",
    "\n",
    "for itr in range(iterations):\n",
    "    feature, label = asvspoof_dev.__getitem__(itr)\n",
    "    #print(\"60 vectors\", feature.T.shape)\n",
    "    print(\"audiofile label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mv ../ASVspoof_2019_baseline_CM_v1/featureLFCC_dev.mat ./datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "\n",
    "mat_dev = hdf5storage.loadmat('./datasets/featureLFCC_dev.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "24844\n"
     ]
    }
   ],
   "source": [
    "#dev_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_dev/flac/*'\n",
    "\n",
    "cm_LA_LFCC = []\n",
    "\n",
    "for i, file in enumerate(glob.glob('../ASVspoof_2019_baseline_CM_v1/dev_dataset/*')):\n",
    "    \n",
    "    features = hdf5storage.loadmat(file)['x_fea']\n",
    "    \n",
    "    label = file.split('_')[-1].rstrip('.mat')\n",
    "    \n",
    "    #print(features.shape, label)\n",
    "    \n",
    "    feature_tensor = torch.from_numpy(features.T).float()\n",
    "    \n",
    "    # compute log-likelihood ratio\n",
    "    score = -(gmm_bonafide.evaluate(feature_tensor) - gmm_spoof.evaluate(feature_tensor))\n",
    "    \n",
    "    cm_LA_LFCC.append((label, score))\n",
    "    \n",
    "print('Done!')\n",
    "print(len(cm_LA_LFCC)) # This should be 24844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_dev/flac/*'\n",
    "\n",
    "cm_LA_LFCC = []\n",
    "\n",
    "for itr, fname in enumerate(glob.glob('./datasets/scaled/dev/lfcc/*')):\n",
    "    \n",
    "    #feature, label = asvspoof_dev.__getitem__(itr)\n",
    "    feature = np.load(fname)\n",
    "    \n",
    "    feature_tensor = torch.from_numpy(feature).float()\n",
    "    \n",
    "    label = fname.split('/')[-1].split('_')[0]\n",
    "    \n",
    "    # compute log-likelihood ratio\n",
    "    score = -(gmm_bonafide.evaluate(feature_tensor) - gmm_spoof.evaluate(feature_tensor))\n",
    "    \n",
    "    cm_LA_LFCC.append((label, score))\n",
    "    \n",
    "print('Done!')\n",
    "print(len(cm_LA_LFCC)) # This should be 24844\n",
    "#np.savetxt('scores_cm_LA_LFCC.txt', score, fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on development set\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cm_LA_LFCC = []\n",
    "\n",
    "for itr in range(len(asvspoof_dev)):\n",
    "    \n",
    "    feature, label = asvspoof_dev.__getitem__(itr)\n",
    "    \n",
    "    if label is None:\n",
    "        continue\n",
    "    \n",
    "    feature_scaled = preprocessing.scale(feature.T)\n",
    "    \n",
    "    feature_tensor = torch.from_numpy(feature_scaled).float()\n",
    "    #print(feature_tensor.shape)\n",
    "    \n",
    "    # compute log-likelihood ratio\n",
    "    score = -(gmm_bonafide.evaluate(feature_tensor) - gmm_spoof.evaluate(feature_tensor))\n",
    "    \n",
    "    cm_LA_LFCC.append((*label, score))\n",
    "\n",
    "print('Done!')\n",
    "print(len(cm_LA_LFCC))\n",
    "#np.savetxt('scores_cm_LA_LFCC.txt', score, fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for evaluation of score with 3-labels\n",
    "with open('./scores/scores_cm_LA_LFCC_torch_itr10_sentence_scaled_v2.txt', mode='w') as f:\n",
    "    \n",
    "    f.write('\\n'.join('{} {} {} {}'.format(spkid, source, key, score) for spkid, source, key, score in cm_LA_LFCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for evaluation of score with 1-label\n",
    "with open('./scores/scores_cm_LA_LFCC_torch_winlen20ms_mat.txt', mode='w') as f:\n",
    "    \n",
    "    f.write('\\n'.join('- - {} {}'.format(key, score) for key, score in cm_LA_LFCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./scores/scores_cm_LA_LFCC_torch_winlen20ms_mat.txt') as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cm_LA_LFCC, './scores/cm_LA_LFCC_torch_itr10_sentence_scaled_v2.score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
