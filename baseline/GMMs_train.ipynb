{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFCC-GMM trainning baseline\n",
    "   #### number of training = 25,380\n",
    "    genuine 2,580 spoof 22,800\n",
    "   \n",
    "   #### number of development = 24,986\n",
    "    genuine 2,548 spoof 22,296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMMs(Gaussian Mixture Models) front-end are LFCCs and CQCCs.\n",
    "# My library\n",
    "from lfcc import *\n",
    "\n",
    "# Library for dataloader\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "# Library for LFCC-GMM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.externals import joblib\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Library for reading flac audio file\n",
    "import soundfile as sf\n",
    "#from scipy.io.wavfile import read\n",
    "\n",
    "# Library for pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_formatter = \"{:.4f}\".format\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind': float_formatter})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproess, Dataset, Dataloader definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(object):\n",
    "    \"\"\"\n",
    "    Preprocessing class for audio data\n",
    "    \n",
    "    Attributes:\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        \"\"\"\n",
    "        self.extractor = None\n",
    "        self.features = None\n",
    "        \n",
    "    def __call__(self, y, sr, feature, dynamic=True):\n",
    "        \"\"\"\n",
    "        Extract fetures with lfcc, mfcc, cqcc and other method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        \"\"\"\n",
    "        if feature == 'LFCC':\n",
    "            self.extractor = LFCC(y, sr)\n",
    "            \n",
    "        elif feature == 'MFCC':\n",
    "            self.extractor = MFCC(y, sr)\n",
    "        \n",
    "        elif feature == 'CQCC':\n",
    "            self.extractor = CQCC(y, sr)\n",
    "        \n",
    "        self.features = self.extractor.extract_feature(delta=True)\n",
    "        \n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test\n",
    "process = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqcc.py\t\t    lfcc_genuine.csv  mfcc.py\t\tutterance3.wav\r\n",
      "genuine_gmms.model  lfcc_gmm.py       __pycache__\r\n",
      "GMMs_train.ipynb    lfcc.py\t      s1260057_report1\r\n",
      "LA_T_1028533.flac   lfcc_spoofed.csv  utterance0.wav\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[-16.5522 -0.4726 0.1725 0.3888 0.1829 0.3511 -0.0702 0.1470 0.1563 0.3022\n",
      " 0.0253 0.2734 -0.0234 0.1721 -0.0298 0.0777 0.0121 0.1056 0.0020 -0.0753\n",
      " 0.0384 -0.2158 -0.3082 -0.2376 -0.1667 0.2446 0.1779 -0.0823 -0.0529\n",
      " -0.2009 0.1487 0.1664 -0.1119 -0.0733 0.2524 -0.2201 0.1062 0.2401 0.2084\n",
      " 0.2276 -0.7961 -0.2876 -0.3175 -0.4325 -0.4009 0.0602 -0.0161 0.0760\n",
      " -0.2515 -0.2867 -0.2888 -0.3918 0.1669 0.0195 -0.1686 0.0731 -0.1411\n",
      " -0.1029 -0.0962 0.0587]\n",
      "(113, 60)\n"
     ]
    }
   ],
   "source": [
    "y, sr = sf.read('LA_T_1028533.flac')\n",
    "\n",
    "print(sr*32//1000)\n",
    "\n",
    "ext = LFCC(y, sr)\n",
    "lfcc = ext.extract_feature(delta=True).T\n",
    "\n",
    "print(lfcc[3])\n",
    "print(lfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_datapath_list(phase='train'):\n",
    "    \"\"\"\n",
    "    make a list containing a path to data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    phase: 'train' or 'dev' or 'eval'\n",
    "        specify whether data is for train or development or evaluation\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    path_list : list\n",
    "        return a list containing a path to data\n",
    "    \"\"\"\n",
    "    \n",
    "    root_path = \"/DB/Audio/English/ASVspoof2019/LA/\"\n",
    "    target_path = os.path.join(root_path+'ASVspoof2019_LA_'+phase+'/flac/*.flac')\n",
    "    print(target_path)\n",
    "    \n",
    "    path_list = []\n",
    "    \n",
    "    # Get a filepath to subdir by using glob module\n",
    "    for path in glob.glob(target_path):\n",
    "        path_list.append(path)\n",
    "    \n",
    "    return path_list\n",
    "\n",
    "# test\n",
    "train_list = make_datapath_list(phase='train')\n",
    "dev_list = make_datapath_list(phase='dev')\n",
    "\n",
    "#print(train_list)\n",
    "\n",
    "#print(dev_list)\n",
    "\n",
    "#print(len(train_list), len(dev_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataloader\n",
    "class ASVspoofDataSet(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for ASVspoof2019, which derived from torch.utils.data.Dataset class\n",
    "    \n",
    "    Attributes:\n",
    "    --------------\n",
    "    file_list: list\n",
    "        list containing a path to data\n",
    "        \n",
    "    transform: object\n",
    "        instance of PreProcessor\n",
    "    \n",
    "    phase: str\n",
    "        'train' or 'dev' or 'eval'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_list, label_list=None, preprocess=None, phase='train'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_list: list\n",
    "            list of audio files to read\n",
    "        \n",
    "        label_list: list\n",
    "            list of labels('bonafide' or 'spoof'), which is changed to 0, 1\n",
    "        \n",
    "        transform: class PreProcess\n",
    "            instance of PreProcess to be used for pre-process to audio data\n",
    "        \n",
    "        phase: str\n",
    "            specify whether data is for training or development or evaluation('train' or 'dev' or 'eval')\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.phase = phase\n",
    "        self.preprocess = preprocess\n",
    "        self.root_path = '/DB/Audio/English/ASVspoof2019/LA/'\n",
    "        #self.file_path = None\n",
    "        self.file_list = file_list\n",
    "        self.label_path = None\n",
    "        self.label_list = label_list\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            self.label_path = os.path.join(self.root_path+'ASVspoof2019_LA_cm_protocols/')\n",
    "            self.label_list = []\n",
    "            with open(self.label_path+'ASVspoof2019.LA.cm.train.trn.txt', mode='r') as protocols:\n",
    "                for line in protocols:\n",
    "                    line = line.split() # read line by line\n",
    "                    filename, label = line[1], line[-1] # get filename and label from protocols file\n",
    "                    self.label_list.append((filename, label))\n",
    "                    \n",
    "        elif self.phase == 'dev':\n",
    "            self.label_path = os.path.join(self.root_path+'ASVspoof2019_LA_cm_protocols/')\n",
    "            self.label_list = []\n",
    "            with open(self.label_path+'ASVspoof2019.LA.cm.dev.trl.txt', mode='r') as protocols:\n",
    "                for line in protocols:\n",
    "                    line = line.split() # read line by line\n",
    "                    filename, label = line[1], line[-1] # get filename and label from protocols file\n",
    "                    self.label_list.append((filename, label))\n",
    "        else:\n",
    "            print(\"You must pass either phase='train' or phase='dev'\")\n",
    "        \n",
    "    def __len__(self): # this is needed to be overrided\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index): # this is also needed to be overrided\n",
    "        \"\"\"\n",
    "        Get data and its label that was pre-processed\n",
    "        \"\"\"\n",
    "        \n",
    "        # load audio\n",
    "        speech_path = self.file_list[index]\n",
    "        speech, sr = sf.read(speech_path)\n",
    "        \n",
    "        # preprocessing and extract features\n",
    "        features = self.preprocess(y=speech, sr=sr, feature='LFCC') # preprocess to speech, not implemented yet\n",
    "        \n",
    "        label = None\n",
    "        speech_name = speech_path.split('/')[-1].rstrip('.flac')\n",
    "        \n",
    "        for fname, la in self.label_list:\n",
    "            #print(fname)\n",
    "            if fname == speech_name: # compare to speech_name with '==' annotation, check if they have same value.\n",
    "                label = la\n",
    "                #print(\"filename: {}, label: {}\".format(fname, label))\n",
    "        \n",
    "        #print(\"sp name:\", speech_name)\n",
    "        return features, label\n",
    "    \n",
    "# test\n",
    "\n",
    "file_list = train_list\n",
    "\n",
    "asvspoof_train = ASVspoofDataSet(file_list=file_list, preprocess=process, phase='train')\n",
    "\n",
    "# get 10 files and its label\n",
    "iterations = 10\n",
    "\n",
    "for itr in range(iterations):\n",
    "    #print(asvspoof_train.file_list[itr])\n",
    "    feature, label = asvspoof_train.__getitem__(itr)\n",
    "    print(\"60 vectors\", feature.T.shape)\n",
    "    print(\"audiofile label: \", label)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMMs training section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters for training\n",
    "\n",
    "LFCCs:\n",
    "\n",
    "    window_len = 20ms\n",
    "    nfft = 512\n",
    "    # of filters = 20\n",
    "    dynamic features = delta, delta-delta included\n",
    "\n",
    "GMMs:\n",
    "\n",
    "    n_components = 512\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# instanciate DataLoader\n",
    "train_dataloader = data.DataLoader(asvspoof_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = None #data.DataLoader()\n",
    "\n",
    "dataloader_dict = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader\n",
    "}\n",
    "\n",
    "batch_iterator = iter(dataloader_dict[\"train\"])\n",
    "inputs, labels = next(batch_iterator) # get first element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_train/flac/*'\n",
    "dev_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_dev/flac/*'\n",
    "\n",
    "speech_count = 0\n",
    "total = len(glob.glob(train_path))\n",
    "print(\"total_speech:\", total)\n",
    "\n",
    "genuine_df = pd.DataFrame()\n",
    "spoofed_df = pd.DataFrame()\n",
    "\n",
    "progress=np.arange(10.0,110.0,10)\n",
    "\n",
    "for itr in range(total):\n",
    "    \n",
    "    prog = speech_count/total*100\n",
    "    if prog in progress:\n",
    "        print('%.2f % complete' % prog)\n",
    "    \n",
    "    feature, label = asvspoof_train.__getitem__(itr)\n",
    "    #print(\"12-dimentional vectors\", feature.T.shape)\n",
    "    #print(\"audiofile label: \", label)\n",
    "    #print()\n",
    "    feature_df = pd.DataFrame(feature.T)\n",
    "    \n",
    "    #print(feature_df.shape)\n",
    "    if label == 'bonafide':\n",
    "        genuine_df = genuine_df.append(feature_df, ignore_index=True)\n",
    "    else:\n",
    "        spoofed_df = spoofed_df.append(feature_df, ignore_index=True)\n",
    "    \n",
    "    speech_count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(genuine_df), len(spoofed_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genuine_df.dropna(inplace=True)\n",
    "genuine_df.reset_index(drop=True).to_csv('./lfcc_genuine.csv', index=False)\n",
    "\n",
    "spoofed_df.dropna(inplace=True)\n",
    "spoofed_df.reset_index(drop=True).to_csv('./lfcc_spoofed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg = pd.read_csv('./lfcc_genuine.csv')\n",
    "Xs = pd.read_csv('./lfcc_spoofed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check count\n",
    "print(len(Xg), len(Xs))\n",
    "# drop nan or inf\n",
    "Xg.dropna(inplace=True)\n",
    "Xs.dropna(inplace=True)\n",
    "\n",
    "Xs.replace([np.inf, -np.inf], np.nan).dropna(inplace=True)\n",
    "# check count again\n",
    "print(len(Xg), len(Xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMMs training\n",
    "# speaker embedding by using GMMs, where n_components = 512\n",
    "n_components = 512\n",
    "\n",
    "genuine_gmms = GaussianMixture(n_components=n_components, covariance_type='diag', max_iter=10, random_state=None)\n",
    "\n",
    "# Train the other parameters using the EM algorithm\n",
    "genuine_gmms.fit(Xg)\n",
    "\n",
    "Xg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = pd.read_csv('./lfcc_spoofed.csv')\n",
    "# check count\n",
    "print(len(Xs))\n",
    "# drop nan or inf\n",
    "Xs.dropna(inplace=True)\n",
    "\n",
    "Xs.replace([np.inf, -np.inf], np.nan).dropna(inplace=True)\n",
    "# check count again\n",
    "print(len(Xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "n_components = 512\n",
    "\n",
    "spoofed_gmms = GaussianMixture(n_components=n_components, covariance_type='diag', max_iter=10, random_state=None)\n",
    "\n",
    "# Train the other parameters using the EM algorithm\n",
    "spoofed_gmms.fit(Xs)\n",
    "\n",
    "Xs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(genuine_gmms, 'genuine_gmms.model')\n",
    "joblib.dump(spoofed_gmms, 'spoofed_gmms.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "asvspoof_dev = ASVspoofDataSet(file_list=dev_list, preprocess=process, phase='dev')\n",
    "\n",
    "# get 10 files and its label\n",
    "iterations = 10\n",
    "\n",
    "for itr in range(iterations):\n",
    "    feature, label = asvspoof_dev.__getitem__(itr)\n",
    "    print(\"60 vectors\", feature.T.shape)\n",
    "    print(\"audiofile label: \", label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dev_path = '/DB/Audio/English/ASVspoof2019/LA/ASVspoof2019_LA_dev/flac/*'\n",
    "\n",
    "speech_count = 0\n",
    "total = len(glob.glob(dev_path))\n",
    "print(\"total_speech:\", total)\n",
    "\n",
    "progress=np.arange(10.0,110.0,10)\n",
    "\n",
    "score = np.array()\n",
    "\n",
    "for itr in range(3):\n",
    "    \n",
    "    prog = speech_count/total*100\n",
    "    if prog in progress:\n",
    "        print('%.2f % complete' % prog)\n",
    "    \n",
    "    feature, label = asvspoof_dev.__getitem__(itr)\n",
    "    \n",
    "    print(genuine_gmms.score(lfccs).shape)\n",
    "    \n",
    "    loglh_genuine = np.mean(genuine_gmms.score(lfccs), axis=0)\n",
    "    loglh_spoofed = np.mean(spoofed_gmms.score(lfccs), axis=0)\n",
    "    \n",
    "    # compute log-likelihood ratio\n",
    "    score = np.append(score, loglh_genuine - loglh_spoofed)\n",
    "\n",
    "# store score to file\n",
    "np.save('scores_cm_LA_LFCC.txt', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scores_cm_LA_LFCC.txt', mode='w') as score_file:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
